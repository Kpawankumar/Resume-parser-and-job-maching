{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy pdfplumber docx2txt scikit-learn\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docx2txt\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, pdfplumber, docx2txt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Function to extract text from PDF or DOCX resumes\n",
    "def extract_text(file_path):\n",
    "\n",
    "    \"\"\"Extracts text from a PDF or DOCX file, removing unnecessary whitespace.\"\"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \" \".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        text = docx2txt.process(file_path)\n",
    "    else:\n",
    "        return \"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# Function to process extracted text and identify relevant information\n",
    "\n",
    "def process_resume(text):\n",
    "    \"\"\"Extracts structured information like skills, education, and experience using NLP and keyword matching.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    extracted_info = {\"Education\": [], \"Experience\": [], \"Skills\": []}\n",
    "\n",
    "    \n",
    "    # Extract Education & Experience using Named Entity Recognition\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"EDUCATION\", \"ORG\"]:  # Organizations like universities\n",
    "            extracted_info[\"Education\"].append(ent.text)\n",
    "        elif ent.label_ in [\"DATE\", \"TIME\"]:  # Dates indicating experience periods\n",
    "            extracted_info[\"Experience\"].append(ent.text)\n",
    "    \n",
    "    # Extract Skills using keyword matching\n",
    "    skill_keywords = {\"python\", \"java\", \"c++\", \"machine learning\", \"data science\", \"nlp\", \"tensorflow\", \"keras\", \"sql\", \"react\", \"django\", \"flask\", \"cloud computing\"}\n",
    "    extracted_info[\"Skills\"] = list(set(word.text.lower() for word in doc if word.text.lower() in skill_keywords))\n",
    "    \n",
    "    return {key: \", \".join(set(value)) if value else \"Not detected\" for key, value in extracted_info.items()}\n",
    "\n",
    "# Function to compare resume with job description\n",
    "def match_job(resume_text, job_desc):\n",
    "    \"\"\"Enhances matching accuracy using TF-IDF with domain-specific stopword removal and bigrams.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "    vectors = vectorizer.fit_transform([resume_text, job_desc])\n",
    "    return round(cosine_similarity(vectors[0], vectors[1])[0][0] * 100, 2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load spaCy NLP model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Get user input for resume file path and job description\n",
    "    file_path = input(\"Enter resume file path (PDF/DOCX): \").strip()\n",
    "    job_desc = input(\"Enter job description: \").strip()\n",
    "    \n",
    "    # Extract, process, and match resume with job description\n",
    "    resume_text = extract_text(file_path)\n",
    "    resume_info = process_resume(resume_text)\n",
    "    match_score = match_job(resume_text, job_desc)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n  Resume Details:\")\n",
    "    for label, value in resume_info.items():\n",
    "        print(f\"{label}: {value}\")\n",
    "    \n",
    "    print(f\"\\n  Job Match Score: {match_score}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
